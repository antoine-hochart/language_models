import os
import torch

from time import time

from utils.data import get_corpus, preprocess_text, list2str
from utils.eval import perplexity_loss
from utils.nn import encode_text, decode_text, Textset
from models.nn import RNNLM

######################################################################
# parameters

MIN_COUNT = 5

EMBEDDING_DIM = 128
HIDDEN_SIZE = 256
SEQ_LEN = 30
BATCH_SIZE = 2048

######################################################################
# load and preprocess text

print("Loading and preprocessing text...")
t0 = time()
text = get_corpus()
(train_text, val_text, test_text), vocab = preprocess_text(
    text, val_size=0.1, test_size=0.1, min_count=MIN_COUNT, seed=0
    )
print("Done ({:.2f}s)".format(time() - t0))
print()

######################################################################
# load model

model = RNNLM(len(vocab), EMBEDDING_DIM, HIDDEN_SIZE, SEQ_LEN)
fpath = os.path.join(os.path.dirname(__file__), '..', 'data', 'models', 'rnn.pt')
model.load_state_dict(torch.load(fpath, map_location=torch.device('cpu')))
model.eval()

######################################################################
# evaluate model

testset = Textset(test_text, vocab, SEQ_LEN)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu") 
print("Computing perplexity on {}...".format(device))
perplexity = perplexity_loss(model, testset, BATCH_SIZE, device)

print("Perplexity of model on test set: {:.2f}".format(perplexity))
print()

######################################################################
# sentence generator

print("Sentences generated by model:")
print()

eos = ['.', '?', '!']
eos = encode_text(eos, vocab)

seed = ['ce', 'soir']
seed = encode_text(seed, vocab)

model.to('cpu')
new_text = model.generate_text(seed, eos, n_sent=5)
new_text = decode_text(new_text, vocab)
new_text = list2str(new_text)

print(new_text)
